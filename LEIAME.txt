# Projeto - Pipeline de MLOps Para Operacionalização e Monitoramento de IA Generativa com LLM e RAG
# Instruções Para Execução do Projeto

# 1- Crie sua conta no HuggingFace, acesse o site abaixo e crie sua chave gratuita (token) para a API:

https://huggingface.co/settings/tokens

# 2- Edite o arquivo abaixo e altere o valor de HUGGINGFACE_KEY para sua chave.

docker-compose.yaml

# 3- Inicialize o Docker Desktop.

# 4- Abra o terminal ou prompt de comando, navegue até a pasta raiz com os arquivos e execute o comando abaixo para criar os containers:

docker-compose up --build -d

# Nota: Será preciso editar 2 arquivos e colocar o nome do hostname do container do ElasticSearch, conforme mostrado nas aulas. 
Abra Docker desktop
Ache o container do ElasticSearch
Clique nos três pontos > Open Terminal > digite bash > digite hostname
Pega nome da máquina
Edita os arquivos 
Pasta jfmmoduloairflow > dags > modulojfmdados > jfm_carrega_dados > hostname função jfm_cria_indice
Pasta jfmmoduloapp > streamlit > app > jfmelasticSearch > função getEsClient

# 5- Abra o navegador e acesse o Airflow para ativar a DAG:
Só ir no container Docker no container do airflow e clicar no link

localhost:8080

username: airflow
password: airflow

# 6- Abra o navegador e acesse a app web para interagir com o LLM (espere alguns segundos até o ElasticSearch finalizar a indexação):

localhost:8501

# Exemplos de perguntas:

# Can the landlord avoid liability for breaching this obligation if the state of disrepair is caused by the tenant's actions?
# Why did the plaintiff wait seven months to file an appeal?
# Can you provide more details on the clarification provided in Note 1?

# 7- Abra o navegador e acesse o Grafana para carregar o dashboard. Siga as instruções das aulas para ajustar a configuração:

localhost:3000

username: admin
password: admin

Home > connections > data sources > add data sources >> pesquise por postgres

host URL:5f69f11343f7:5432
Docker > container airflow_postgres > três pontinho > open in terminal> bash > hostname

database: ariflow
username:
senha

importar o dashboard
dashboards > new > import
pega arquivo json na pasta do grafana e arrasta
executa as queries em cada caixa


# Envie perguntas na app de IA Generativa e monitore pelo Dashboard do Grafana.

# Fim




